{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import params\n",
    "from model import GradTTS\n",
    "from data import TextMelSpeakerDataset, TextMelSpeakerBatchCollate\n",
    "from utils import plot_tensor, save_plot\n",
    "from text.symbols import symbols\n",
    "from model.utils import sequence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filelist_path = params.train_filelist_path\n",
    "valid_filelist_path = params.valid_filelist_path\n",
    "\n",
    "cmudict_path = params.cmudict_path\n",
    "add_blank = params.add_blank\n",
    "n_spks = params.n_spks\n",
    "spk_emb_dim = params.spk_emb_dim\n",
    "\n",
    "log_dir = params.log_dir\n",
    "n_epochs = params.n_epochs\n",
    "batch_size = params.batch_size\n",
    "out_size = params.out_size\n",
    "learning_rate = params.learning_rate\n",
    "random_seed = params.seed\n",
    "\n",
    "nsymbols = len(symbols) + 1 if add_blank else len(symbols)\n",
    "n_enc_channels = params.n_enc_channels\n",
    "filter_channels = params.filter_channels\n",
    "filter_channels_dp = params.filter_channels_dp\n",
    "n_enc_layers = params.n_enc_layers\n",
    "enc_kernel = params.enc_kernel\n",
    "enc_dropout = params.enc_dropout\n",
    "n_heads = params.n_heads\n",
    "window_size = params.window_size\n",
    "\n",
    "n_feats = params.n_feats\n",
    "n_fft = params.n_fft\n",
    "sample_rate = params.sample_rate\n",
    "hop_length = params.hop_length\n",
    "win_length = params.win_length\n",
    "f_min = params.f_min\n",
    "f_max = params.f_max\n",
    "\n",
    "dec_dim = params.dec_dim\n",
    "beta_min = params.beta_min\n",
    "beta_max = params.beta_max\n",
    "pe_scale = params.pe_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextMelSpeakerDataset(train_filelist_path, cmudict_path, add_blank,\n",
    "                                          n_fft, n_feats, sample_rate, hop_length,\n",
    "                                          win_length, f_min, f_max)\n",
    "batch_collate = TextMelSpeakerBatchCollate()\n",
    "loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                    collate_fn=batch_collate, drop_last=True,\n",
    "                    num_workers=8, shuffle=True)\n",
    "test_dataset = TextMelSpeakerDataset(valid_filelist_path, cmudict_path, add_blank,\n",
    "                                        n_fft, n_feats, sample_rate, hop_length,\n",
    "                                        win_length, f_min, f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/xingxing/anaconda3/envs/gradtts/lib/python3.6/site-packages/torch/functional.py:573: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x', 'x_lengths', 'y', 'y_lengths', 'speaker', 'spk', 'emo'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_lengths = batch['x'], batch['x_lengths']\n",
    "y, y_lengths = batch['y'], batch['y_lengths']\n",
    "speaker, spk, emo = batch['speaker'], batch['spk'], batch['emo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_emb = torch.nn.Linear(256, spk_emb_dim)\n",
    "emo_emb = torch.nn.Linear(768, spk_emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk = spk_emb(spk)\n",
    "emo = emo_emb(emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 32]), torch.Size([16, 32]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk.shape, emo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(nsymbols, n_enc_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x = emb(x) * math.sqrt(n_enc_channels)\n",
    "x = torch.transpose(x, 1, -1)\n",
    "x_mask = torch.unsqueeze(sequence_mask(x_lengths, x.size(2)), 1).to(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 101])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.text_encoder import ConvReluNorm, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prenet = ConvReluNorm(n_enc_channels, n_enc_channels, n_enc_channels, \n",
    "                        kernel_size=5, n_layers=3, p_dropout=0.5)\n",
    "\n",
    "x = prenet(x, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([x, spk.unsqueeze(-1).repeat(1, 1, x.shape[-1])], dim=1)\n",
    "x = torch.cat([x, emo.unsqueeze(-1).repeat(1, 1, x.shape[-1])], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 101])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(n_enc_channels + spk_emb_dim * 2, filter_channels, n_heads, n_enc_layers, \n",
    "                    enc_kernel, enc_dropout, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encoder(x, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 101])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
